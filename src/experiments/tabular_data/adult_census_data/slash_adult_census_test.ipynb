{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3da80b51-4a68-4815-95da-cec730619673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import csv\n",
    "from data_generation import getDataset, A, B, C, get_data_and_query_list, get_data_and_query_list_classification\n",
    "from tabnet_nn import TabNetClass\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../tabnet/')\n",
    "import torch\n",
    "from tabnet.pytorch_tabnet.tab_model import TabNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c14e6211-a6a2-480e-ac27-a397c4f243a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists.\n",
      "Pick the indeces at random and save these as the file for the future usage.\n",
      "['train' 'train' 'train' ... 'train' 'train' 'test']\n",
      "39 73\n",
      " State-gov 9\n",
      " Bachelors 16\n",
      " 13 16\n",
      " Never-married 7\n",
      " Adm-clerical 15\n",
      " Not-in-family 6\n",
      " White 5\n",
      " Male 2\n",
      " 2174 119\n",
      " 0 92\n",
      " 40 94\n",
      " United-States 42\n",
      " <=50K 2\n",
      "Set 3\n",
      "12.208180247896188\n",
      "-4.687234513184198\n",
      "1484705\n",
      "0\n",
      "mean = [2.16001988e+01 3.86833856e+00 1.90070309e+05 1.02918801e+01\n",
      " 9.07431761e+00 2.61407600e+00 6.55008028e+00 1.44502638e+00\n",
      " 3.66526493e+00 6.68552642e-01 6.49950302e+00 2.10180442e+00\n",
      " 3.93903968e+01 3.66984097e+01]\n",
      "std = [1.36873420e+01 1.45538642e+00 1.06046492e+05 3.86621842e+00\n",
      " 2.58057349e+00 1.50703802e+00 4.22331326e+00 1.60381798e+00\n",
      " 8.47475477e-01 4.70733478e-01 2.32651434e+01 1.01749545e+01\n",
      " 1.21632046e+01 7.82943740e+00]\n"
     ]
    }
   ],
   "source": [
    "cat_idxs, cat_dims, X_train, y_train, X_test, y_test, X_valid, y_valid = getDataset()\n",
    "# train_im = (train_im - train_im_mean) / (train_im_std + std_eps)\n",
    "# test_im = (test_im - train_im_mean) / (train_im_std + std_eps)\n",
    "std_eps = 1e-7\n",
    "# mean = 13663371\n",
    "# std = 432617472\n",
    "# mean = np.array([13957.98828125, 13745.662109375, 13167.2392578125, 13569.68359375, 13949.2998046875, 13651.0263671875, 14229.9130859375, 13707.5029296875, 13638.5478515625, 13973.296875, 13208.11328125, 13414.619140625, 13221.68359375, 13849.091796875])\n",
    "# std = np.array([56801.58203125, 59977.14453125, 52696.41015625, 55285.53515625, 55181.80078125, 56164.78125, 58817.890625, 57530.44921875, 56601.30859375, 54942.81640625, 54631.1953125, 51787.45703125, 59670.05078125, 56394.84375])\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "X_train_normalized = (X_train - mean) / (std + std_eps)\n",
    "X_test_normalized = (X_test - mean) / (std + std_eps)\n",
    "print(X_train_normalized.max())\n",
    "print(X_train_normalized.min())\n",
    "print(X_train.max())\n",
    "print(X_train.min())\n",
    "print(f'mean = {mean}')\n",
    "print(f'std = {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f56c200-ebd4-405b-8015-6bf7783a0d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_generation.A\n"
     ]
    }
   ],
   "source": [
    "A_train = A(X_train_normalized, y_train)\n",
    "A_test = A(X_test_normalized, y_test)\n",
    "print(type(A_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04c9dc88-5973-473c-94cf-80e2a64c018a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8398,  1.4668, -1.0121, -0.3383,  1.1368, -0.4086, -0.6078, -0.9002,\n",
      "         0.3923,  0.7037, -0.2780, -0.2039, -2.2536,  0.2920],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.83717175,  1.46359766, -1.01201848, -0.33905836,  1.13665943,\n",
       "       -0.40861388, -0.60658108, -0.90002736,  0.39246116,  0.70261754,\n",
       "       -0.27988366, -0.20426352, -2.25120837,  0.29130398])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(A_train[0][0])\n",
    "print(A_train[0][1])\n",
    "print(len(A_train[0][0]))\n",
    "X_train_normalized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba2f0bf7-af33-4a21-bda4-bf92a3633a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26117\n",
      "3225\n"
     ]
    }
   ],
   "source": [
    "print(len(A_train))\n",
    "print(len(A_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51d80322-899d-47c2-ab11-9765e9cd96c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mark = 'train'\n",
    "data_file = Path(os.getcwd()+'/data/'+mark+'_data.txt')\n",
    "with open(data_file, 'w') as f:\n",
    "    if len(dummy) % 2 == 1:\n",
    "        n = len(dummy)-1\n",
    "    else: \n",
    "        n = len(dummy)\n",
    "    for i in np.arange(0, n, 2):\n",
    "        f.write(str(i)+' '+str(dummy[i]['X'][9])+' '+str(i+1)+' '+str(dummy[i+1]['X'][9]))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da309f66-4f43-455a-8a0d-77bf0e0b28b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(A_test, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(A_test, batch_size=100, shuffle=True)\n",
    "for data, target in test_loader:\n",
    "    print(type(data))\n",
    "    print(type(target))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1a64734-6672-4ed8-b7bb-76c5dc0d3935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_generation.B\n"
     ]
    }
   ],
   "source": [
    "train_dataset = B(dataset=A_train, examples='data/train_data.txt')\n",
    "print(type(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53c7c5f1-78af-4cd7-9671-b385f17c3692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 0.9867,  1.4668,  0.1894,  0.1797, -0.4212, -0.4086, -0.6078, -0.9002,\n",
      "         0.3923,  0.7037, -0.2780, -0.2039,  0.3775,  0.2920],\n",
      "       dtype=torch.float64), 1)\n",
      "tensor([0.1475, 0.0861, 0.1352, 0.1258, 0.0442, 0.0389, 0.0330, 0.0316, 0.1958,\n",
      "        0.1617], grad_fn=<SoftmaxBackward>)\n",
      "[{'p': tensor([ 0.8398,  1.4668, -1.0121, -0.3383,  1.1368, -0.4086, -0.6078, -0.9002,\n",
      "         0.3923,  0.7037, -0.2780, -0.2039, -2.2536,  0.2920],\n",
      "       dtype=torch.float64)}\n",
      " {'p': tensor([-0.0416,  0.0919,  0.2465,  0.1797, -0.4212, -1.7359, -0.1342, -0.2779,\n",
      "         0.3923,  0.7037, -0.2780, -0.2039, -0.0336,  0.2920],\n",
      "       dtype=torch.float64)}\n",
      " {'p': tensor([ 0.9867,  1.4668,  0.1894,  0.1797, -0.4212, -0.4086, -0.6078, -0.9002,\n",
      "         0.3923,  0.7037, -0.2780, -0.2039,  0.3775,  0.2920],\n",
      "       dtype=torch.float64)}\n",
      " ...\n",
      " {'p': tensor([ 1.0601,  0.0919,  1.2567,  0.4387,  1.5263, -0.4086, -0.6078, -0.9002,\n",
      "         0.3923,  0.7037, -0.2780, -0.2039, -0.0336,  0.2920],\n",
      "       dtype=torch.float64)}\n",
      " {'p': tensor([-1.2167,  0.0919,  1.1453,  1.2158, -0.0317,  0.9187,  1.0498, -0.2779,\n",
      "         0.3923,  0.7037, -0.2780, -0.2039, -0.0336,  0.2920],\n",
      "       dtype=torch.float64)}\n",
      " {'p': tensor([-0.8495,  0.0919,  0.6427, -0.8563,  0.7473, -0.4086,  1.5234,  2.2117,\n",
      "         0.3923, -1.4210, -0.2780, -0.2039, -0.1980,  0.2920],\n",
      "       dtype=torch.float64)}]\n"
     ]
    }
   ],
   "source": [
    "print(A_train[2])\n",
    "dataList, queryList = get_data_and_query_list_classification(A_train)\n",
    "# print(torch.nn.Softmax(A_train[2], dim=1))\n",
    "# print(torch.tensor(A_train[2][0]).softmax())\n",
    "# print(A_train[2][0].softmax())\n",
    "print(torch.nn.Softmax(dim=0)(torch.randn(10, requires_grad=True)))\n",
    "# print(train_dataset[49])\n",
    "print(dataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c5b1545-852e-4d5d-b7be-ad351468442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList, queryList = get_data_and_query_list(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b240a5a-d954-40cc-a171-84951f75e40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":- not wealth_gap(p1,0,p2,1).\n",
      "{'p1': tensor([-0.1884,  0.0919, -1.1361,  1.2158, -0.0317, -1.7359, -1.3182,  1.5893,\n",
      "        -1.9825, -1.4210, -0.2780, -0.2039, -0.0336,  0.2920],\n",
      "       dtype=torch.float64), 'p2': tensor([-0.1884, -1.2831,  1.8347, -0.3383,  1.1368, -1.7359, -1.3182,  1.5893,\n",
      "         0.3923, -1.4210, -0.2780, -0.2039, -0.4447, -2.6524],\n",
      "       dtype=torch.float64)}\n",
      "torch.Size([14])\n"
     ]
    }
   ],
   "source": [
    "print(queryList[123])\n",
    "print(dataList[123])\n",
    "print(dataList[123]['p1'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f21f7-56cb-4f51-acd7-2da62da46daf",
   "metadata": {},
   "source": [
    "# Test TabNet wrapper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9412defc-175c-443f-a461-0c338810968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TabNetClass(cat_idxs=cat_idxs, cat_dims=cat_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "327dd628-a4c8-4b28-a100-f1e1fa8d501b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2619,  1.4668,  0.3855,  ..., -0.2039, -0.0336,  0.2920],\n",
      "        [ 1.2805,  1.4668, -0.9982,  ..., -0.2039, -0.0336,  0.2920],\n",
      "        [-0.7760,  0.0919, -0.0438,  ..., -0.2039,  1.1176,  0.2920],\n",
      "        ...,\n",
      "        [-0.2619,  0.0919, -1.4046,  ..., -0.2039, -0.8558,  0.2920],\n",
      "        [ 0.1053,  0.7793, -0.1335,  ..., -0.2039,  0.8709,  0.2920],\n",
      "        [-0.4088,  1.4668,  0.0586,  ..., -0.2039,  0.3775,  0.2920]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "tmp = []\n",
    "for batch in train_loader:\n",
    "    print(batch[0])\n",
    "    tmp = batch[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03f2dab7-0b1c-48d5-8321-9a03578433f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-1cc372a20da3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparsity_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/splpmln/slash_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/splpmln/src/slash_adult_census_income/tabnet_nn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, sparsity_loss)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mM_loss\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparsity_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/splpmln/slash_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/splpmln/src/tabnet/pytorch_tabnet/tab_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtabnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/splpmln/slash_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/splpmln/src/tabnet/pytorch_tabnet/tab_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                 cols.append(\n\u001b[0;32m--> 861\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat_feat_counter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_init_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 )\n\u001b[1;32m    863\u001b[0m                 \u001b[0mcat_feat_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/splpmln/slash_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/splpmln/slash_env/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/splpmln/slash_env/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "print(clf(tmp, sparsity_loss=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74b3090e-a566-45c6-af11-457b12888562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tabnet_nn.TabNetClass'>\n"
     ]
    }
   ],
   "source": [
    "print(type(clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f48c9995-4044-4743-bfcf-7e47bffaf2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original string is : geeks4geeks\n",
      "Does string contain any digit ? : True\n",
      "Yeap! It wörks!\n"
     ]
    }
   ],
   "source": [
    "# Python3 code to demonstrate working of \n",
    "# Check if string contains any number\n",
    "# Using isdigit() + any()\n",
    "  \n",
    "# initializing string\n",
    "test_str = 'geeks4geeks'\n",
    "  \n",
    "# printing original string\n",
    "print(\"The original string is : \" + str(test_str))\n",
    "  \n",
    "# using any() to check for any occurrence\n",
    "res = any(chr.isdigit() for chr in test_str)\n",
    "      \n",
    "# printing result \n",
    "print(\"Does string contain any digit ? : \" + str(res)) \n",
    "\n",
    "if any(chr.isdigit() for chr in test_str):\n",
    "    print('Yeap! It wörks!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fe0e4be7-b002-41c4-8347-23276c5dd6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13957.98828125, 13745.662109375, 13167.2392578125, 13569.68359375, 13949.2998046875, 13651.0263671875, 14229.9130859375, 13707.5029296875, 13638.5478515625, 13973.296875, 13208.11328125, 13414.619140625, 13221.68359375, 13849.091796875]\n",
      "[56801.58203125, 59977.14453125, 52696.41015625, 55285.53515625, 55181.80078125, 56164.78125, 58817.890625, 57530.44921875, 56601.30859375, 54942.81640625, 54631.1953125, 51787.45703125, 59670.05078125, 56394.84375]\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "train_loader = torch.utils.data.DataLoader(A_train,\n",
    "                                           batch_size=100,\n",
    "                                           shuffle=True)\n",
    "loader = torch.utils.data.DataLoader(train_loader, batch_size=len(train_loader), num_workers=1)\n",
    "num_of_pixels = len(train_loader) * 14\n",
    "col_num = np.arange(14)\n",
    "mean_vec = []\n",
    "std_vec = []\n",
    "for c in col_num:\n",
    "    total_sum = 0\n",
    "    # print(f'Column number {c}')\n",
    "    for batch in train_loader:\n",
    "        total_sum += batch[0][c].sum()\n",
    "    mean = total_sum / num_of_pixels\n",
    "    mean_vec.append(float(mean))\n",
    "    # print(f'\\t mean = {mean}')\n",
    "    sum_of_squared_error = 0\n",
    "    for batch in train_loader: \n",
    "        sum_of_squared_error += ((batch[0][c] - mean).pow(2)).sum()\n",
    "    std = torch.sqrt(sum_of_squared_error / num_of_pixels)\n",
    "    std_vec.append(float(std))\n",
    "    # print(f'\\t std = {std}')\n",
    "print(mean_vec)\n",
    "print(std_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97b2c69b-47c7-4235-ac76-879f7bceb1e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'transforms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d9b8bdb5fd55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                            \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                            \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                            transforms=transforms.Compose([transforms.Normalize(mean, std)]))\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'transforms'"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "train_loader = torch.utils.data.DataLoader(A_train,\n",
    "                                           batch_size=1024,\n",
    "                                           shuffle=True\n",
    "                                           ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "800ff8ab-5ea5-4387-ae5f-056a4542f6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "29dff697-5c46-405a-b37f-3aa4703f965d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "263e9042-700a-4f49-b07d-9d1a7742d9bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TabNet' object has no attribute 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-1205b3f80765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/splpmln/slash_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1131\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TabNet' object has no attribute 'batch_size'"
     ]
    }
   ],
   "source": [
    "print(clf.network.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bfca2ad-cd15-470e-94e1-3b9f17ede91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = C(dataset=A_train, examples='data/classification_train_data.txt')\n",
    "test_dataset = C(dataset=A_test, examples='data/classification_test_data.txt')\n",
    "dataList, queryList = get_data_and_query_list_classification(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3cbe807-e7b9-4db1-9706-6d88e4c872c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[':- not wealthy(p,0).' ':- not wealthy(p,0).' ':- not wealthy(p,0).' ...\n",
      " ':- not wealthy(p,1).' ':- not wealthy(p,0).' ':- not wealthy(p,0).']\n",
      "25978\n"
     ]
    }
   ],
   "source": [
    "print(queryList)\n",
    "print(len(queryList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d56040e7-1803-4dcd-a90b-18d7b1940da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'p': tensor([   33,     6, 83311,     9,    12,     2,     4,     0,     4,     1,\n",
      "            0,     0,    12,    39], dtype=torch.int32)}\n",
      " {'p': tensor([    21,      4, 215646,     11,      8,      0,      6,      1,      4,\n",
      "             1,      0,      0,     39,     39], dtype=torch.int32)}\n",
      " {'p': tensor([    36,      4, 234721,      1,      6,      2,      6,      0,      2,\n",
      "             1,      0,      0,     39,     39], dtype=torch.int32)}\n",
      " ...\n",
      " {'p': tensor([     8,      2, 514716,      9,     12,      4,      1,      3,      2,\n",
      "             0,      0,      0,     39,     39], dtype=torch.int32)}\n",
      " {'p': tensor([     3,      4, 270436,     11,      8,      4,      7,      3,      4,\n",
      "             1,      0,      0,     39,     39], dtype=torch.int32)}\n",
      " {'p': tensor([   29,     4, 42972,    12,    13,     2,    10,     5,     4,     0,\n",
      "            0,     0,    21,    39], dtype=torch.int32)}]\n"
     ]
    }
   ],
   "source": [
    "print(dataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fb818e4d-1942-4740-ab7d-52f361e49ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists.\n",
      "39 73\n",
      " State-gov 9\n",
      " Bachelors 16\n",
      " 13 16\n",
      " Never-married 7\n",
      " Adm-clerical 15\n",
      " Not-in-family 6\n",
      " White 5\n",
      " Male 2\n",
      " 2174 119\n",
      " 0 92\n",
      " 40 94\n",
      " United-States 42\n",
      " <=50K 2\n",
      "Set 3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "dataset_name = 'census-income'\n",
    "data_file = Path(os.getcwd()+'/data/'+dataset_name+'.csv')\n",
    "data_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "if data_file.exists():\n",
    "    print(\"File already exists.\")\n",
    "else:\n",
    "    print(\"Downloading file...\")\n",
    "    wget.download(url, data_file.as_posix())\n",
    "# 2. Load the data and split accordingly\n",
    "train = pd.read_csv(data_file)\n",
    "target = ' <=50K'\n",
    "if \"Set\" not in train.columns:\n",
    "    train[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p =[.8, .1, .1], size=(train.shape[0],))\n",
    "train_indices = train[train.Set==\"train\"].index\n",
    "valid_indices = train[train.Set==\"valid\"].index\n",
    "test_indices = train[train.Set==\"test\"].index\n",
    "# 3. Label encode categorical features and fill empty cells.\n",
    "nunique = train.nunique()\n",
    "types = train.dtypes\n",
    "categorical_columns = []\n",
    "categorical_dims =  {}\n",
    "for col in train.columns:\n",
    "    if types[col] == 'object' or nunique[col] < 200:\n",
    "        print(col, train[col].nunique())\n",
    "        l_enc = LabelEncoder()\n",
    "        train[col] = train[col].fillna(\"VV_likely\")\n",
    "        train[col] = l_enc.fit_transform(train[col].values)\n",
    "        categorical_columns.append(col)\n",
    "        categorical_dims[col] = len(l_enc.classes_)\n",
    "    else:\n",
    "        train.fillna(train.loc[train_indices, col].mean(), inplace=True)\n",
    "# 4. Define categorical features for categorical embeddings\n",
    "unused_feat = ['Set']\n",
    "features = [ col for col in train.columns if col not in unused_feat+[target]] \n",
    "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]\n",
    "# 5. Define the data subsets.\n",
    "X_train = train[features].values[train_indices]\n",
    "y_train = train[target].values[train_indices]\n",
    "X_test = train[features].values[test_indices]\n",
    "y_test = train[target].values[test_indices]\n",
    "X_valid = train[features].values[valid_indices]\n",
    "y_valid = train[target].values[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "610e9227-ea75-429f-a9ac-5e691ebf685d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "32555    0\n",
       "32556    1\n",
       "32557    2\n",
       "32558    2\n",
       "32559    1\n",
       "Name: Set, Length: 32560, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Set\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ee53f108-d07d-464f-8e6d-8d123c6c01f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists. Load the indices...\n",
      "['valid' 'train' 'train' ... 'valid' 'train' 'train']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "indices_file = Path(os.getcwd()+'/data/indices.npy')\n",
    "indices_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "indices = []\n",
    "if indices_file.exists():\n",
    "    print(\"File already exists. Load the indices...\")    \n",
    "    indices = np.load(indices_file)\n",
    "else:    \n",
    "    print(\"Pick the indeces at random and save these as the file for the future usage.\")\n",
    "    indices = np.random.choice([\"train\", \"valid\", \"test\"], p =[.8, .1, .1], size=(train.shape[0],))\n",
    "    np.save(indices_file, indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a07910d8-c60d-4ccb-a5da-e38dae42c770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['train', 'test', 'train'], dtype='<U5')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeces[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1b47534f-b81e-47a3-828b-372ca60ab2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indeces_file = Path(os.getcwd()+'/data/indices.npy')\n",
    "array = np.load(indeces_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "49b684dc-7ffc-4628-a7ef-5fee38afd37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype='<U5')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0156c97-bdff-4b11-b1bf-36e47170fed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
